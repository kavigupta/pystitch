{"update.py": "import dataclasses\nimport io\nimport itertools\nimport logging\nimport os\nimport pathlib\nimport re\nimport shutil\nimport subprocess\nimport sys\nimport tarfile\nimport tempfile\nimport textwrap\nfrom collections.abc import Iterable, Iterator, Mapping, Sequence\nfrom datetime import datetime, timezone\n\nimport click\nimport parver  # type: ignore\nimport requests\n\nIANA_LATEST_LOCATION = \"https://www.iana.org/time-zones/repository/tzdata-latest.tar.gz\"\nSOURCE = \"https://data.iana.org/time-zones/releases\"\nWORKING_DIR = pathlib.Path(\"tmp\")\nREPO_ROOT = pathlib.Path(__file__).parent\nPKG_BASE = REPO_ROOT / \"src\"\nTEMPLATES_DIR = REPO_ROOT / \"templates\"\n\nSKIP_NEWS_HEADINGS = {\n    \"Changes to code\",\n    \"Changes to build procedure\",\n}\n\n\ndef download_tzdb_tarballs(\n    version: str, base_url: str = SOURCE, working_dir: pathlib.Path = WORKING_DIR\n) -> Sequence[pathlib.Path]:\n    \"\"\"Download the tzdata and tzcode tarballs.\"\"\"\n    tzdata_file = f\"tzdata{version}.tar.gz\"\n    tzcode_file = f\"tzcode{version}.tar.gz\"\n\n    target_dir = working_dir / version / \"download\"\n    # mkdir -p target_dir\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    download_locations = []\n    for filename in [tzdata_file, tzcode_file]:\n        download_location = target_dir / filename\n        download_locations.append(download_location)\n\n        if download_location.exists():\n            logging.info(\"File %s already exists, skipping\", download_location)\n            continue\n\n        url = f\"{base_url}/{filename}\"\n        logging.info(\"Downloading %s from %s\", filename, url)\n\n        r = requests.get(url)\n        with open(download_location, \"wb\") as f:\n            f.write(r.content)\n\n    return download_locations\n\n\ndef retrieve_local_tarballs(\n    version: str, source_dir: pathlib.Path, working_dir: pathlib.Path = WORKING_DIR\n) -> Sequence[pathlib.Path]:\n    \"\"\"Retrieve the tzdata and tzcode tarballs from a folder.\n\n    This is useful when building against a local, patched version of tzdb.\n    \"\"\"\n    tzdata_file = f\"tzdata{version}.tar.gz\"\n    tzcode_file = f\"tzcode{version}.tar.gz\"\n\n    target_dir = working_dir / version / \"download\"\n\n    # mkdir -p target_dir\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    dest_locations = []\n\n    for filename in [tzdata_file, tzcode_file]:\n        source_location = source_dir / filename\n        dest_location = target_dir / filename\n\n        if dest_location.exists():\n            logging.info(\"File %s exists, overwriting\", dest_location)\n\n        shutil.copy(source_location, dest_location)\n\n        dest_locations.append(dest_location)\n\n    return dest_locations\n\n\ndef unpack_tzdb_tarballs(\n    download_locations: Sequence[pathlib.Path],\n) -> pathlib.Path:\n    assert len(download_locations) == 2\n    assert download_locations[0].parent == download_locations[1].parent\n    base_dir = download_locations[0].parent.parent\n    target_dir = base_dir / \"tzdb\"\n\n    # Remove the directory and re-create it if it does not exist\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    target_dir.mkdir()\n\n    for tarball in download_locations:\n        logging.info(\"Unpacking %s to %s\", tarball, target_dir)\n        subprocess.run(\n            [\"tar\", \"-xf\", os.fspath(tarball.absolute())],\n            cwd=target_dir,\n            check=True,\n        )\n\n    return target_dir\n\n\ndef load_zonefiles(\n    base_dir: pathlib.Path,\n) -> tuple[Sequence[str], pathlib.Path]:\n    target_dir = base_dir.parent / \"zoneinfo\"\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    with tempfile.TemporaryDirectory() as td:\n        td_path = pathlib.Path(td)\n\n        # First run the makefile, which does all kinds of other random stuff\n        subprocess.run(\n            [\"make\", f\"DESTDIR={td}\", \"POSIXRULES=\", \"ZFLAGS=-b slim\", \"install\"],\n            cwd=base_dir,\n            check=True,\n        )\n\n        proc = subprocess.run(\n            [\"make\", \"zonenames\"], cwd=base_dir, stdout=subprocess.PIPE, check=True\n        )\n        zonenames = list(map(str.strip, proc.stdout.decode(\"utf-8\").split(\"\\n\")))\n\n        # Move the zoneinfo files into the target directory\n        src_dir = td_path / \"usr\" / \"share\" / \"zoneinfo\"\n        shutil.move(os.fspath(src_dir), os.fspath(target_dir))\n\n    return zonenames, target_dir\n\n\ndef create_package(version: str, zonenames: Sequence[str], zoneinfo_dir: pathlib.Path):\n    \"\"\"Creates the tzdata package.\"\"\"\n    # Start out at rc0\n    base_version = parver.Version.parse(translate_version(version))\n    rc_version = base_version.replace(pre_tag=\"rc\", pre=0)\n    package_version = str(rc_version)\n\n    # First remove the existing package contents\n    target_dir = PKG_BASE / \"tzdata\"\n    if target_dir.exists():\n        shutil.rmtree(target_dir)\n\n    data_dir = target_dir / \"zoneinfo\"\n\n    # Next move the zoneinfo file to the target location\n    shutil.move(os.fspath(zoneinfo_dir), data_dir)\n\n    # Generate the base __init__.py from a template\n    with open(TEMPLATES_DIR / \"__init__.py.in\", \"r\") as f_in:\n        contents = f_in.read()\n        contents = contents.replace(\"%%IANA_VERSION%%\", f'\"{version}\"')\n        contents = contents.replace(\"%%PACKAGE_VERSION%%\", f'\"{package_version}\"')\n\n        with open(target_dir / \"__init__.py\", \"w\") as f_out:\n            f_out.write(contents)\n\n    with open(REPO_ROOT / \"VERSION\", \"w\") as f:\n        f.write(package_version)\n\n    # Generate the \"zones\" file as a newline-delimited list\n    with open(target_dir / \"zones\", \"w\") as f:\n        f.write(\"\\n\".join(zonenames))\n\n    # Now recursively create __init__.py files in every directory we need to\n    for dirpath, _, filenames in os.walk(data_dir):\n        if \"__init__.py\" not in filenames:\n            init_file = pathlib.Path(dirpath) / \"__init__.py\"\n            init_file.touch()\n\n\ndef find_latest_version() -> str:\n    r = requests.get(IANA_LATEST_LOCATION)\n    fobj = io.BytesIO(r.content)\n    with tarfile.open(fileobj=fobj, mode=\"r:gz\") as tf:\n        vfile = tf.extractfile(\"version\")\n\n        assert vfile is not None, \"version file is not a regular file\"\n        version = vfile.read().decode(\"utf-8\").strip()\n\n    assert re.match(\"\\d{4}[a-z]$\", version), version\n\n    target_dir = WORKING_DIR / version / \"download\"\n    target_dir.mkdir(parents=True, exist_ok=True)\n\n    fobj.seek(0)\n    with open(target_dir / f\"tzdata{version}.tar.gz\", \"wb\") as f:\n        f.write(fobj.read())\n\n    return version\n\n\ndef translate_version(iana_version: str) -> str:\n    \"\"\"Translates from an IANA version to a PEP 440 version string.\n\n    E.g. 2020a -> 2020.1\n    \"\"\"\n\n    if (\n        len(iana_version) < 5\n        or not iana_version[0:4].isdigit()\n        or not iana_version[4:].isalpha()\n    ):\n        raise ValueError(\n            \"IANA version string must be of the format YYYYx where YYYY represents the \"\n            f\"year and x is in [a-z], found: {iana_version}\"\n        )\n\n    version_year = iana_version[0:4]\n    patch_letters = iana_version[4:]\n\n    # From tz-link.html:\n    #\n    # Since 1996, each version has been a four-digit year followed by\n    # lower-case letter (a through z, then za through zz, then zza through zzz,\n    # and so on).\n    if len(patch_letters) > 1 and not all(c == \"z\" for c in patch_letters[0:-1]):\n        raise ValueError(\n            f\"Invalid IANA version number (only the last character may be a letter \"\n            f\"other than z), found: {iana_version}\"\n        )\n\n    final_patch_number = ord(patch_letters[-1]) - ord(\"a\") + 1\n    patch_number = (26 * (len(patch_letters) - 1)) + final_patch_number\n\n    return f\"{version_year}.{patch_number:d}\"\n\n\n##\n# News entry handling\n@dataclasses.dataclass\nclass NewsEntry:\n    version: str\n    release_date: datetime\n    categories: Mapping[str, str]\n\n    def to_file(self) -> None:\n        fpath = pathlib.Path(\"news.d\") / (self.version + \".md\")\n        release_date = self.release_date.astimezone(timezone.utc)\n        translated_version = translate_version(self.version)\n\n        contents = [f\"# Version {translated_version}\"]\n        contents.append(\n            f\"Upstream version {self.version} released {release_date.isoformat()}\"\n        )\n        contents.append(\"\")\n\n        for category, entry in self.categories.items():\n            contents.append(f\"## {category}\")\n            contents.append(\"\")\n            contents.append(entry)\n            contents.append(\"\")\n\n        with open(fpath, \"wt\") as f:\n            f.write((\"\\n\".join(contents)).strip())\n\n\nINDENT_RE = re.compile(\"[^ ]\")\n\n\ndef get_indent(s: str) -> int:\n    s = s.rstrip()\n    if not s:\n        return 0\n\n    m = INDENT_RE.search(s)\n    assert m is not None\n    return m.span()[0]\n\n\ndef read_block(\n    lines: Iterator[str],\n) -> tuple[Sequence[str], Iterator[str]]:\n    lines, peek = itertools.tee(lines)\n    while not (first_line := next(peek)):\n        next(lines)\n\n    block_indent = get_indent(first_line)\n    block = []\n\n    # The way this loop works: `peek` is always one line ahead of `lines`. It\n    # starts out where `lines` is pointing to the first non-empty line, and\n    # peek is the line after that. We know that if the body of the loop is\n    # reached, the next value in `lines` is part of the block.\n    #\n    # It is done this way so that we can return an iterable pointing at the\n    # first line *after* the block that we just read.\n    for line in peek:\n        block.append(next(lines))\n\n        if not line:\n            block.append(line)\n            continue\n\n        line_indent = get_indent(line)\n        if line_indent < block_indent:\n            # We've dedented, so this is the end of the block.\n            break\n    else:\n        # If we've exhausted `peek` because we're reading the last block in the\n        # file, we won't hit the `break` condition, but we'll still have a\n        # valid line in the `lines` queue.\n        block.append(next(lines))\n\n    return block, lines\n\n\ndef parse_categories(news_block: Sequence[str]) -> Mapping[str, str]:\n    blocks = iter(news_block)\n\n    output = {}\n    while True:\n        try:\n            while not (heading := next(blocks)):\n                pass\n        except StopIteration:\n            break\n\n        content_lines, blocks = read_block(blocks)\n\n        heading = heading.strip()\n        if heading in SKIP_NEWS_HEADINGS:\n            continue\n\n        # Merge the contents into paragraphs by grouping into consecutive blocks\n        # of non-empty lines, then joining those lines on a newline.\n        content_paragraphs: Iterable[str] = (\n            \"\\n\".join(paragraph)\n            for _, paragraph in itertools.groupby(content_lines, key=bool)\n        )\n\n        # Now dedent each paragraph and wrap it to 80 characters. This needs to\n        # be done at the per-paragraph level, because `textwrap.wrap` doesn't\n        # recognize paragraph breaks.\n        content_paragraphs = map(textwrap.dedent, content_paragraphs)\n        content_paragraphs = map(\n            \"\\n\".join,\n            (textwrap.wrap(paragraph, width=80) for paragraph in content_paragraphs),\n        )\n\n        # Finally we can join the paragraphs into a single string and trim\n        # whitespace from it\n        contents = \"\\n\".join(content_paragraphs)\n        contents = contents.strip()\n\n        output[heading] = contents\n\n    return output\n\n\ndef read_news(tzdb_loc: pathlib.Path, version: str | None = None) -> NewsEntry:\n    release_re = re.compile(\"^Release (?P<version>\\d{4}[a-z]) - (?P<date>.*$)\")\n    with open(tzdb_loc / \"NEWS\", \"rt\") as f:\n        f_lines = map(str.rstrip, f)\n        for line in f_lines:\n            if ((m := release_re.match(line)) is not None) and (\n                version is None or m.group(\"version\") == version\n            ):\n                break\n        else:\n            if version is None:\n                message = \"No releases found!\"\n            else:\n                message = f\"No release found with version {version}\"\n\n        assert m is not None\n        version_date = datetime.strptime(m.group(\"date\"), \"%Y-%m-%d %H:%M:%S %z\")\n        release_version = m.group(\"version\")\n        release_contents, _ = read_block(f_lines)\n\n    # Now we further parse the contents of the news and filter out some\n    # irrelevant categories.\n    categories = parse_categories(release_contents)\n\n    return NewsEntry(release_version, version_date, categories)\n\n\ndef update_news(news_entry: NewsEntry):\n    # news.d contains fragments for each tzdata version, and the NEWS file\n    # is assembled by stitching these together each time. First thing we'll do\n    # is add a new fragment.\n    news_entry.to_file()\n\n    # Now go through and join all the files together\n    news_fragment_files = sorted(\n        pathlib.Path(\"news.d\").glob(\"*.md\"), key=lambda p: p.name, reverse=True\n    )\n\n    news_fragments = [p.read_text() for p in news_fragment_files]\n\n    with open(\"NEWS.md\", \"wt\") as f:\n        f.write(\"\\n\\n---\\n\\n\".join(news_fragments))\n\n\n@click.command()\n@click.option(\n    \"--version\", \"-v\", default=None, help=\"The version of the tzdata file to download\"\n)\n@click.option(\n    \"--source-dir\",\n    \"-s\",\n    default=None,\n    help=\"A local source directory containing tarballs (must be used together with --version)\",\n    type=click.Path(\n        exists=True, file_okay=False, dir_okay=True, path_type=pathlib.Path\n    ),  # type: ignore\n)\n@click.option(\n    \"--news-only/--no-news-only\",\n    help=\"Flag to disable data updates and only update the news entry\",\n)\ndef main(\n    version: str | None,\n    news_only: bool,\n    source_dir: pathlib.Path | None,\n):\n    logging.basicConfig(level=logging.INFO)\n\n    if source_dir is not None:\n        if version is None:\n            logging.error(\n                \"--source-dir specified without --version: \"\n                \"If using --source-dir, --version must also be used.\"\n            )\n            sys.exit(-1)\n        download_locations = retrieve_local_tarballs(version, source_dir)\n    else:\n        if version is None:\n            version = find_latest_version()\n\n        download_locations = download_tzdb_tarballs(version)\n\n    tzdb_location = unpack_tzdb_tarballs(download_locations)\n\n    # Update the news entry\n    news_entry = read_news(tzdb_location, version=version)\n    update_news(news_entry)\n\n    if not news_only:\n        zonenames, zonefile_path = load_zonefiles(tzdb_location)\n        create_package(version, zonenames, zonefile_path)\n\n\nif __name__ == \"__main__\":\n    main()\n", "bump_version.py": "import argparse\nimport io\nimport pathlib\n\nimport parver  # type: ignore\n\nREPO_ROOT = pathlib.Path(__file__).parent\nVERSION = REPO_ROOT / pathlib.Path(\"VERSION\")\n\n\ndef get_current_version() -> parver.Version:\n    with open(VERSION, \"rt\") as f:\n        return parver.Version.parse(f.read().strip())\n\n\ndef write_version(version: parver.Version):\n    with open(VERSION, \"wt\") as f:\n        f.write(str(version))\n\n\ndef update_package_version(version: parver.Version):\n    new_init = io.StringIO()\n    version_set = False\n    init = REPO_ROOT / \"src\" / \"tzdata\" / \"__init__.py\"\n    with open(init, \"rt\") as f:\n        for line in f:\n            if not version_set and line.startswith(\"__version__\"):\n                line = f'__version__ = \"{version}\"\\n'\n                version_set = True\n            new_init.write(line)\n\n    if not version_set:\n        raise ValueError(\"Version not found in __init__.py!\")\n\n    new_init.seek(0)\n\n    with open(init, \"wt\") as f:\n        f.write(new_init.read())\n\n\ndef bump_version(version: parver.Version, args) -> parver.Version:\n    if args.release:\n        return version.base_version()\n\n    if args.dev:\n        if args.to is not None:\n            return version.replace(dev=args.to)\n        else:\n            return version.bump_dev()\n\n    version = version.replace(dev=None)\n\n    if args.post:\n        if args.to is not None:\n            return version.replace(post=args.to)\n        else:\n            return version.bump_post()\n\n    if args.rc:\n        if version.is_postrelease:\n            version = version.replace(post=None)\n\n        if args.to is not None:\n            return version.replace(pre_tag=\"rc\", pre=args.to)\n        else:\n            return version.bump_pre(\"rc\")\n\n    return version\n\n\ndef main(args):\n    original_version = get_current_version()\n    bumped_version = bump_version(original_version, args)\n\n    print(f\"{original_version} \u2192 {bumped_version}\")\n    if not args.dry_run:\n        write_version(bumped_version)\n        update_package_version(bumped_version)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Manipulate the package version\")\n\n    group = parser.add_mutually_exclusive_group(required=True)\n\n    group.add_argument(\"--rc\", action=\"store_true\", help=\"Bump the release candidate\")\n    group.add_argument(\"--dev\", action=\"store_true\", help=\"Bump the dev version\")\n    group.add_argument(\n        \"--release\",\n        action=\"store_true\",\n        help=\"Bump from release candidate / dev to release\",\n    )\n    group.add_argument(\n        \"--post\", action=\"store_true\", help=\"Bump the post release version\"\n    )\n    parser.add_argument(\n        \"--to\",\n        type=int,\n        default=None,\n        help=\"Set the specified component to a specific number\",\n    )\n    parser.add_argument(\n        \"--dry-run\",\n        action=\"store_true\",\n        help=\"Preview what the new version will be without writing any files.\",\n    )\n\n    args = parser.parse_args()\n\n    if args.to is not None and args.release:\n        raise ValueError(\"Cannot combine --to and --release\")\n\n    main(args)\n"}